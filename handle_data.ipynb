{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "RANDOM_STATE: np.int8 = 42\n",
    "TEST_SIZE: np.float64 = 0.2\n",
    "\n",
    "MAXIMUM_UNIT_LENGTH_STAY: np.int32 = 24\n",
    "NUMBER_OF_BINS: np.int8 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data from comorbidades and capacidade funcional, plus ages and labels\n",
    "df: pd.DataFrame = pd.read_csv(\"data/folha3.csv\")\n",
    "ages: pd.Series = df[\"Age\"].copy()\n",
    "df: pd.DataFrame = df[df[\"UnitLengthStay\"].apply(lambda x: x <= MAXIMUM_UNIT_LENGTH_STAY)].copy()\n",
    "df.dropna(axis=1, thresh=5000, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "labels: pd.DataFrame = df[\"UnitLengthStay\"].copy()\n",
    "df = df.iloc[:, 22:]\n",
    "sheet_3_df: pd.DataFrame = (df == \"Verdadeiro\").astype(int)\n",
    "\n",
    "# getting data from motivos de internação na UTI\n",
    "df = pd.read_csv(\"data/folha4.csv\")\n",
    "df: pd.DataFrame = df[df[\"UnitLengthStay\"].apply(lambda x: x <= MAXIMUM_UNIT_LENGTH_STAY)].copy()\n",
    "df = df.iloc[:, 21:]\n",
    "df.dropna(axis=1, thresh=5000, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)\n",
    "sheet_4_df: pd.DataFrame = (df == \"Verdadeiro\").astype(int)\n",
    "\n",
    "# joining dataframes\n",
    "final_data: pd.DataFrame = pd.concat([ages, sheet_3_df, sheet_4_df], axis=1, join=\"inner\")\n",
    "\n",
    "labels_regression: pd.DataFrame = labels.copy()\n",
    "labels_classification: pd.DataFrame = pd.cut(x=labels_regression, bins=[0, 2, MAXIMUM_UNIT_LENGTH_STAY], labels=np.arange(NUMBER_OF_BINS))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    final_data, labels_regression, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "NUMBER_OF_ESTIMATORS: np.int32 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.977336987241147"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=NUMBER_OF_ESTIMATORS)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.60385834710524"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=NUMBER_OF_ESTIMATORS)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    final_data, labels_classification, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "NUMBER_OF_ESTIMATORS: np.int32 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.60496614, 0.57282343])"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=NUMBER_OF_ESTIMATORS)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6286117 , 0.53731343])"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(n_estimators=NUMBER_OF_ESTIMATORS)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3664            2.01s\n",
      "         2           1.3552            1.97s\n",
      "         3           1.3458            1.96s\n",
      "         4           1.3382            1.99s\n",
      "         5           1.3315            1.90s\n",
      "         6           1.3259            1.80s\n",
      "         7           1.3205            1.73s\n",
      "         8           1.3159            1.76s\n",
      "         9           1.3114            1.75s\n",
      "        10           1.3075            1.70s\n",
      "        20           1.2793            1.49s\n",
      "        30           1.2620            1.45s\n",
      "        40           1.2504            1.48s\n",
      "        50           1.2416            1.38s\n",
      "        60           1.2322            1.30s\n",
      "        70           1.2248            1.24s\n",
      "        80           1.2176            1.18s\n",
      "        90           1.2115            1.13s\n",
      "       100           1.2055            1.07s\n",
      "       200           1.1573            0.67s\n",
      "       300           1.1229            0.33s\n",
      "       400           1.0924            0.00s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.66756575, 0.54139535])"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(n_estimators=NUMBER_OF_ESTIMATORS)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
